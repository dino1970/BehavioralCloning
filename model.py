# -*- coding: utf-8 -*-
"""
Created on Tue Nov 14 16:40:06 2017

@author: Mugdim
"""

import csv
import cv2
import numpy as np

lines = []
images = []
measurements = []

# read .csv file already provided
with open('data/driving_log.csv') as csvfile:
    reader = csv.reader(csvfile)
    for line in reader:
        lines.append(line)

# corrections for center, left and right cameras respectively        
corrections = [0,0.4,-0.4] 

# read already provided images and measurements 
for line in lines:
    measurement = float(line[3])
    for i in range(3): # data comes from 3 cameras: center, left and right 
        source_path = line[i]
        filename = source_path.split('/')[-1]
        current_path = 'data/IMG/'+ filename
        image = cv2.imread(current_path)
        images.append(image)
        measurements.append(measurement + corrections[i])   
   

new_images = 1; # use new generated images by own drives

# read images and measurements generated by own drives 
if new_images:    
   lines = []
   with open('data_new/driving_log.csv') as csvfile:
        reader = csv.reader(csvfile)
        for line in reader:
            lines.append(line)
   for line in lines:
       measurement = float(line[3])
       for i in range(3): # data comes from 3 cameras: center, left and right
           source_path = line[i]
           filename = source_path.split('/')[-1]
           current_path = filename
           image = cv2.imread(current_path)
           images.append(image)
           measurements.append(measurement + corrections[i])

# augmented images and measurements by flipping
augmented_images = []
augmented_measurements = []

for image, measurement in zip(images, measurements):
    augmented_images.append(image)
    augmented_measurements.append(measurement)
    augmented_images.append(cv2.flip(image,1))
    augmented_measurements.append(measurement*-1.0)
    

X_train = np.array(augmented_images) # train data
y_train = np.array(augmented_measurements) # train commands

from keras.models import Sequential
from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout

from keras.layers.convolutional import Convolution2D
#from keras.layers.pooling import MaxPooling2D

model = Sequential()
# data normalization
model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape =(160,320,3)))

# cropping to take only the relevant parts of the images
model.add(Cropping2D(cropping=((40,20), (0,0))))

""" NN Model according to NVIDIA: 
5 Convolution layers and 4 fully connected layers with dropping as regularization""" 
DRATE = 0.2 # dropp out rate

model.add(Convolution2D(24,5,5, subsample = (2,2), activation="relu"))
model.add(Dropout(DRATE))
model.add(Convolution2D(36,5,5, subsample = (2,2), activation="relu"))
model.add(Dropout(DRATE))
model.add(Convolution2D(48,5,5, subsample = (2,2), activation="relu"))
model.add(Dropout(DRATE))
model.add(Convolution2D(64,3,3, activation="relu"))
model.add(Dropout(DRATE))
model.add(Convolution2D(64,3,3, activation="relu"))
model.add(Dropout(DRATE))

model.add(Flatten())
model.add(Dense(100))
model.add(Dropout(DRATE))    
model.add(Dense(50))
model.add(Dropout(DRATE))
model.add(Dropout(DRATE))
model.add(Dense(10))
model.add(Dropout(DRATE))
model.add(Dense(1))

# use mean square error cost function and adam optimizer 
model.compile(loss='mse', optimizer = 'adam')
# train model
model.fit(X_train, y_train, validation_split=0.2, shuffle = True, nb_epoch = 5
          )
# save model
model.save('model.h5')